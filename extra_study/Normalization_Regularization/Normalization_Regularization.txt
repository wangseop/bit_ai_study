Normalization : 데이터의 범위를 사용자가 원하는 범위로 제한하는 것으로 픽셀값을 예를 들면 0~255 사이 값들을 최대값인 255로 나누어주어 0~1.0 사이 값으로 매핑시켜주는 것이다.
위 예를 수식으로 풀어쓰면 (정규화하고자 하는 값 - 데이터 값들 중 최소값) / (데이터 값들 중 최대값 - 데이터 값들 중 최소값) 가 된다.
- 사용 목적 : 학습을 더 빨리하고 Local optimum에 빠지는 가능성을 줄이는 등의 실용적 이유로 Normailzation을 해주게 된다.

Regularization : 오버피팅은 훈련 데이터가 적고  매개변수가 많아 표현력이 높은 모델을 사용할 때 발생할 수 있다. 오버피팅이 발생하게 되면 모델이 시험 데이터에 제대로 반응하지 못하는 경우가 생기는데 이를 방지하기 위해서 오버피팅을 막는 Regularization을 사용하게 된다. 
 Regularization 기법의 대표적인 사용법은 L2 Regularization이다. 이는 오버피팅이 weight 값이 커서 발생하는 경우가 많기 때문에 weight가 크다면 큰 페널티를 주어 오버피팅을 억제시키는 방법이다.

- 사용 목적 : 오버피팅을 억제하기 위해 사용한다.
